# analysing-data
Projeto utilizando Metabase + PostgreSQL + Apache Spark + Portainer

# Introdu√ß√£o 
O projeto tem como intuito realizar a inser√ß√£o de dados utilizando processamento mem√≥ria atrav√©s dos Apache Spark, foi realizado um estudo de caso com base nos dados de vendas de video games (open dataset disponibilizado no Kaggle). 

O Apache Spark est√° realizando o processamento dos dados que est√£o contidos nos arquivo/arquivos de vendas e realiza a inser√ß√£o dos dados no banco de dados PostgreSQL. Ap√≥s o armazenamento dos dados no PostgreSQL √© realizada a visualiza√ß√£o destes dados utilizando o Metabase.

Por fim, ser√° utilizado o Prometheus para monitorar todos os servi√ßos em produ√ß√£o.

# Proposta
A proposta √© realizar a implanta√ß√£o dos servi√ßos utilizando Docker.

# Processo de Instala√ß√£o:
Para realizar a instala√ß√£o dos servi√ßos abaixo √© necess√°rio realizar a instala√ß√£o do docker, para isso utilize estarei explicando como instalar o Docker Engine no Linux.

1. Faca uma atualiza√ß√£o dos pacotes e utilize o apt para realizar a instala√ß√£o dos pacotes informados abaixo:
```sh
$ sudo apt-get update

$ sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
```

2. Adicione a chave GPG oficial do Docker:
```sh
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
```

3. Para encontrar a chave use o comando:
```sh
$ apt-key list
```

4. Verifique que voc√™ agora tem a chave como a impress√£o digital do tipo ```9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88```, pegue os oito √∫ltimos digitos.
```sh
$ apt-key fingerprint 0EBFCD88
```

6. Use o seguinte comando para configurar o reposit√≥rio est√°vel:
```sh
$ add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"
```

7. Atualize os pacotes novamente, utilizando o ```apt```:
```sh
$ apt-get update
```

8. Para instalar a ultima vers√£o podemos executar o seguinte comando::
```sh
$ apt-get install docker-ce docker-ce-cli containerd.io
```

9. Verifique a vers√£o do docker para "confirmar" a instala√ß√£o:
```sh
$ docker --version
```

# PostgreSQL
Com o Docker instalado, vamos instalar o PostgreSQL

1. Realizar o pull da imagem:
```sh
$ docker pull postgres
```

2. Verifique se a imagem foi baixada com sucesso:
```sh
$ docker images
```

3. Ap√≥s isso vamos criar uma pasta para servir de volume para o docker:
```sh
$ mkdir -p $HOME/docker/volumes/postgres
```

3. Vamos executar o container ```(Lembrando, em "POSTGRES_PASSWORD", utilize a senha que preferir)```:
```sh
$ docker run --name pg-docker-meta -e POSTGRES_PASSWORD=docker -d -p 5432:5432 -v $HOME/docker/volumes/postgres:/var/lib/postgresql/data  postgres
```

# Metabase
Com o Docker e o PostgreSQL instalados, podemos dar continuidade e realizar a instala√ß√£o do Metabase, nosso principal servi√ßo de visualiza√ß√£o de dados üòÑ.

1. Vamos criar uma pasta para alocar o volume: 
```sh
$ mkdir -p $HOME/docker/volumes/metabase-data
```

2. Vamos executar o container: 
```sh
$ docker run -d -p 3000:3000 --name metabase metabase/metabase
```

3. Aguarde at√© subir o servi√ßo na porta 3000

4. Clique em "Vamos comecar" para realizar todos os processos de acesso, primeiramente voc√™ ir√° definir o idioma e ap√≥s isso definir√° um e-mail de administrador.

# Apache Spark
Para realizarmos a instala√ß√£o do Apache Spark, estaremos utilizando uma distribui√ß√£o do mesmo que √© PySpark, o PySpark √© o Spark em Python, trazendo uma versatilidade ao realizarmos a cria√ß√£o dos c√≥digos, o Apache Spark foi escrito em Scala, por√©m n√£o estaremos abordando neste tutorial.

Vamos realizar a instala√ß√£o do Jupyter Notebook com o PySpark.

1. Podemos executar o container:
```sh
$ docker run -d -p 8888:8888 jupyter/pyspark-notebook
```

2. Ao executar o container, utilize o seguinte comando para realizar a captura do Token de acesso a dashboard do Jupyter Notebook.
```sh
$ docker logs *nome_do_container*
```

Analisando os logs, pode captar o Token atrav√©s da url que cont√©m o mesmo, geralmente est√° descrito como ```"?token="```

Ap√≥s realizar todos os procedimentos, basta realizar o upload do notebook e do dataset disponibilizado neste reposit√≥rio, para comecar a realizar os processamentos. 

# Portainer

Vamos instalar o nosso servi√ßo de monitoramento.

1. Podemos baixar a imagem:
```sh
$ docker pull portainer/portainer
```

2. Vamos executar o container:
```sh
$ docker run -d -p 9000:9000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v /home/renatogroffe/Desenvolvimento/Portainer/data:/data portainer/portainer
```

3. Defina um usu√°rio e uma senha de administrador

4. Selecione a op√ß√£o Local e clique em "Connect"